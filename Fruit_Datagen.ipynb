{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fruit_Datagen.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOCgrCvT4H3MMmXV4nsl84X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gsenas/deeplearning/blob/master/Fruit_Datagen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBaykRQJKIs_"
      },
      "source": [
        "En primer lugar, descargamos el dataset de fruits-360 de [github](https://github.com/Horea94/Fruit-Images-Dataset/archive/master.zip)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMFRdeI0Jorj",
        "outputId": "ee6e557d-5cb3-480a-8a8e-07c934474bbd"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import os as os\r\n",
        "\r\n",
        "_URL = 'https://github.com/Horea94/Fruit-Images-Dataset/archive/master.zip'\r\n",
        "\r\n",
        "zip_file = tf.keras.utils.get_file(origin=_URL, fname='Fruit-Images-Dataset-master.zip', extract=True, cache_subdir='/content')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/Horea94/Fruit-Images-Dataset/archive/master.zip\n",
            "792723456/Unknown - 37s 0us/step"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El_DaLToR8fX"
      },
      "source": [
        "Establecemos los parámetros iniciales de tamaño de imagen y directorio donde buscar las fotos de frutas.\r\n",
        "\r\n",
        "En este caso estamos aumentando las imágenes de prueba, rotando y modificando los tamaños para tener un dataset mayor por cada fruta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dd8NXEZSEWp",
        "outputId": "1f2d98f8-12f9-4a74-cdf2-502025a9d23e"
      },
      "source": [
        "base_dir = './Fruit-Images-Dataset-master/Training'\r\n",
        "\r\n",
        "IMAGE_SIZE = 224\r\n",
        "BATCH_SIZE = 64\r\n",
        "\r\n",
        "#datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, rotation range=30,width_shift_range=0.3,height_shift_range=0.3,horizontal_flip=True,validation_split=0.1,fill_mode='nearest')\r\n",
        "\r\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\r\n",
        "    rescale=1./255,\r\n",
        "    rotation_range=30,\r\n",
        "    width_shift_range=0.3,\r\n",
        "    height_shift_range=0.3,\r\n",
        "    horizontal_flip=True,\r\n",
        "    validation_split=0.1,\r\n",
        "    fill_mode='nearest'\r\n",
        ")\r\n",
        "\r\n",
        "train_generator = datagen.flow_from_directory(base_dir, target_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE, subset='training') "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 60955 images belonging to 131 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPNow8rTXg_9"
      },
      "source": [
        "Nos aseguramos de que estamos obteniendo todas las frutas, y las imprimimos en el fichero de etiquetas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuOqHsn-Xcew",
        "outputId": "10cd45ee-f466-455d-d9af-02eaebeb0d35"
      },
      "source": [
        "print(train_generator.class_indices)\r\n",
        "\r\n",
        "labels = '\\n'.join(sorted((train_generator.class_indices.keys())))\r\n",
        "\r\n",
        "with open('labels.txt','w') as f:\r\n",
        "  f.write(labels)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Apple Braeburn': 0, 'Apple Crimson Snow': 1, 'Apple Golden 1': 2, 'Apple Golden 2': 3, 'Apple Golden 3': 4, 'Apple Granny Smith': 5, 'Apple Pink Lady': 6, 'Apple Red 1': 7, 'Apple Red 2': 8, 'Apple Red 3': 9, 'Apple Red Delicious': 10, 'Apple Red Yellow 1': 11, 'Apple Red Yellow 2': 12, 'Apricot': 13, 'Avocado': 14, 'Avocado ripe': 15, 'Banana': 16, 'Banana Lady Finger': 17, 'Banana Red': 18, 'Beetroot': 19, 'Blueberry': 20, 'Cactus fruit': 21, 'Cantaloupe 1': 22, 'Cantaloupe 2': 23, 'Carambula': 24, 'Cauliflower': 25, 'Cherry 1': 26, 'Cherry 2': 27, 'Cherry Rainier': 28, 'Cherry Wax Black': 29, 'Cherry Wax Red': 30, 'Cherry Wax Yellow': 31, 'Chestnut': 32, 'Clementine': 33, 'Cocos': 34, 'Corn': 35, 'Corn Husk': 36, 'Cucumber Ripe': 37, 'Cucumber Ripe 2': 38, 'Dates': 39, 'Eggplant': 40, 'Fig': 41, 'Ginger Root': 42, 'Granadilla': 43, 'Grape Blue': 44, 'Grape Pink': 45, 'Grape White': 46, 'Grape White 2': 47, 'Grape White 3': 48, 'Grape White 4': 49, 'Grapefruit Pink': 50, 'Grapefruit White': 51, 'Guava': 52, 'Hazelnut': 53, 'Huckleberry': 54, 'Kaki': 55, 'Kiwi': 56, 'Kohlrabi': 57, 'Kumquats': 58, 'Lemon': 59, 'Lemon Meyer': 60, 'Limes': 61, 'Lychee': 62, 'Mandarine': 63, 'Mango': 64, 'Mango Red': 65, 'Mangostan': 66, 'Maracuja': 67, 'Melon Piel de Sapo': 68, 'Mulberry': 69, 'Nectarine': 70, 'Nectarine Flat': 71, 'Nut Forest': 72, 'Nut Pecan': 73, 'Onion Red': 74, 'Onion Red Peeled': 75, 'Onion White': 76, 'Orange': 77, 'Papaya': 78, 'Passion Fruit': 79, 'Peach': 80, 'Peach 2': 81, 'Peach Flat': 82, 'Pear': 83, 'Pear 2': 84, 'Pear Abate': 85, 'Pear Forelle': 86, 'Pear Kaiser': 87, 'Pear Monster': 88, 'Pear Red': 89, 'Pear Stone': 90, 'Pear Williams': 91, 'Pepino': 92, 'Pepper Green': 93, 'Pepper Orange': 94, 'Pepper Red': 95, 'Pepper Yellow': 96, 'Physalis': 97, 'Physalis with Husk': 98, 'Pineapple': 99, 'Pineapple Mini': 100, 'Pitahaya Red': 101, 'Plum': 102, 'Plum 2': 103, 'Plum 3': 104, 'Pomegranate': 105, 'Pomelo Sweetie': 106, 'Potato Red': 107, 'Potato Red Washed': 108, 'Potato Sweet': 109, 'Potato White': 110, 'Quince': 111, 'Rambutan': 112, 'Raspberry': 113, 'Redcurrant': 114, 'Salak': 115, 'Strawberry': 116, 'Strawberry Wedge': 117, 'Tamarillo': 118, 'Tangelo': 119, 'Tomato 1': 120, 'Tomato 2': 121, 'Tomato 3': 122, 'Tomato 4': 123, 'Tomato Cherry Red': 124, 'Tomato Heart': 125, 'Tomato Maroon': 126, 'Tomato Yellow': 127, 'Tomato not Ripened': 128, 'Walnut': 129, 'Watermelon': 130}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tVYvuJpzaeK"
      },
      "source": [
        "Preparamos un modelo secuencial que acumule varias capas. Al ejecutarlo no debería dar errores.\r\n",
        "\r\n",
        "La densidad es 131 porque es el número de etiquetas diferentes que tenemos en el dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFv4D-S0yeQI",
        "outputId": "be454569-6997-4643-b614-74fc75066aca"
      },
      "source": [
        "IMG_SHAPE=(IMAGE_SIZE, IMAGE_SIZE, 3)\r\n",
        "\r\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\r\n",
        "\r\n",
        "base_model.trainable = False\r\n",
        "\r\n",
        "model = tf.keras.Sequential([\r\n",
        "  base_model,\r\n",
        "  tf.keras.layers.Conv2D(32,3,activation='relu'),\r\n",
        "  tf.keras.layers.Dropout(0.2),\r\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\r\n",
        "  tf.keras.layers.Dense(131,activation='softmax')\r\n",
        "])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDqnzTTmz0kq"
      },
      "source": [
        "Finalmente, compilamos la primera versión del modelo, y la ejecutamos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnK591FYz3Ag"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\r\n",
        "              loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSBfoFtL0FNy",
        "outputId": "39935bc6-22e0-4f34-9f6b-36d189990d2a"
      },
      "source": [
        "epochs=10\r\n",
        "\r\n",
        "history= model.fit(train_generator, epochs=epochs, steps_per_epoch=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "200/200 [==============================] - 143s 672ms/step - loss: 4.1359 - accuracy: 0.1234\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 132s 661ms/step - loss: 1.3439 - accuracy: 0.6261\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 132s 660ms/step - loss: 0.6724 - accuracy: 0.7975\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 132s 661ms/step - loss: 0.5262 - accuracy: 0.8326\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 134s 670ms/step - loss: 0.4126 - accuracy: 0.8699\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 135s 675ms/step - loss: 0.3434 - accuracy: 0.8916\n",
            "Epoch 7/10\n",
            " 40/200 [=====>........................] - ETA: 1:46 - loss: 0.3025 - accuracy: 0.8983"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iB03H3772bcJ"
      },
      "source": [
        "Una vez entrenado, exportamos el modelo, y lo descargamos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6L2MK_yn2f-x"
      },
      "source": [
        "saved_model_dir=''\r\n",
        "tf.saved_model.save(model, saved_model_dir)\r\n",
        "\r\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\n",
        "tflite_model = converter.convert()\r\n",
        "\r\n",
        "with open('model.tflite','wb') as f:\r\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwYBP7PL2vlG"
      },
      "source": [
        "\r\n",
        "\r\n",
        "from google.colab import files\r\n",
        "\r\n",
        "files.download('model.tflite')\r\n",
        "files.download('labels.txt')\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}